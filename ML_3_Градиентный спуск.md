#ML #анализ_данных 
# Введение

В [[ML_2_Линейная_Регрессия | предыдущей статье]] мы вывели аналитическую формулу для обучения линейной регрессии с квадратичным функционалом. Однако редко у какой модели бывает аналитическое решение, хочется иметь универсальный подход, который позволяет обучать множество разных моделей. Такой подход есть - Градиентный спуск

# [[ML_Градиент | Градиент вводная статья]]

# Градиентный спуск

Итак, мы знаем что антиградиент указывает на направление наискорейшего убывания функции. Можно выбрать какую-нибудь стартовую точку, допустим вес w_0 и начать по антиградиенту искать минимум (локальный или глобальный пока неизвестно).  Формула обновления весов будет такая:

$$w^{(k)} = w^{(k-1)} - \eta_k \nabla Q(w^{(k-1)})$$
Здесь
$\eta_k$  - это длина шага  
$\nabla Q(w^{(k-1)})$ - это градиент функционала ошибки

## Длина шага

Верно, что от длины шага зависит, как скоро сойдется наша модель и сойдется ли она вообще. Если мы выберем слишком большой шаг, то минимум можно перескочить, если же шаг будет слишком маленьким, то минимума можно достигать очень долго. Поэтому шаг выбирают не константным, а с какой-то логикой сходимости.

## Остановка

Очень важно правильно определить, где остановиться. Вот несколько вариантов.

- При близости градиента к нулю.
- При малом изменении весов.
- Отслеживание ошибки на отложенной выборке и остановка, если ошибка не уменьшается.

## Условия сходимости к глобальному минимуму

- Функция должна быть выпуклой и дифференцируемой.
- Правильный выбор длины шага.
- Оценка сходимости: $$ Q(w^{(k)}) - Q(w^*) = O(\frac{1}{k}) $$
# Оценивание градиента

Зачастую, функционал $Q(w) = \sum_{i = 1}^{l}{q_i(w)}$ отдельные функции $q_i(w)$ соответствуют ошибкам на индивидуальных обьектах. 

Это может быть очень трудоёмко при больших размерах выборки. В то же время точное вычисление градиента может быть не так уж необходимо — как правило, мы делаем не очень большие шаги в сторону антиградиента, и наличие в нём неточностей не должно сильно сказаться на общей траектории. Опишем несколько способов оценивания полного градиента.

## Стохастический градиентный спуск

Оценить градиент суммы функций можно градиентом одного случайно взятого слагаемого: $$\nabla Q(w) \approx \nabla_w q_{i}(w) $$
То есть, если каждый раз заменять полный функционал ошибки на какое-нибудь случайное слагаемое $i$ то можно значительно уменьшить затраты на вычисление.

$$w^{(k)} = w^{(k-1)} - \eta_k \nabla q_i(w^{(k-1)})$$
У обычного градиентного спуска есть важная особенность: чем ближе текущая точка к минимуму, тем меньше в ней градиент, за счёт чего процесс замедляется и аккуратно попадает в окрестность минимума. В случае со стохастическим градиентным спуском это свойство теряется. На каждом шаге мы двигаемся в сторону, оптимальную с точки зрения уменьшения ошибки на одном объекте. Параметры, оптимальные для средней ошибки на всей выборке, не обязаны являться оптимальными для ошибки на одном из объектов. Поэтому SGD метод запросто может отдаляться от минимума, даже оказавшись рядом с ним. Чтобы исправить эту проблему, важно в SGD делать длину шага убывающей — тогда в окрестности оптимума мы уже не сможем делать длинные шаги и, как следствие, не сможем из этой окрестности выйти. Разумеется, потребуется выбирать формулу для длины шага аккуратно, чтобы не остановиться слишком рано и не уйти от минимума.

Отметим одно важное преимущество метода стохастического градиентного спуска. Для выполнения одного шага в данном методе требуется вычислить градиент лишь одного слагаемого — а поскольку одно слагаемое соответствует ошибке на одном объекте, то получается, что на каждом шаге необходимо держать в памяти всего один объект из выборки. Данное наблюдение позволяет обучать линейные модели на очень больших выборках: можно считывать объекты с диска по одному, и по каждому делать один шаг метода SGD.

## SAG

требуется дополнение
# Модификации градиентного спуска

требуется дополнение


Читать следующей [[ML_4_Классификация | Статья про классификацию]]
