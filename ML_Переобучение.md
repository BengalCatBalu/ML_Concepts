#ML #анализ_данных 
# Определение

Нередко в машинном обучении модель оказывается переобученной — её качество на новых данных существенно хуже качества на обучающей выборке.

Действительно, при обучении мы требуем от модели лишь хорошего качества на обучающей выборке, и совершенно не очевидно, почему она должна при этом хорошо обобщать эти результаты на новые объекты. 

Рассмотрим некоторую одномерную выборку, значения единственного признака x в которой генерируются равномерно на отрезке [0, 1], а значения целевой переменной выбираются по формуле y = cos(1.5πx) + N (0, 0.01), где N (µ, σ2 ) — нормальное распределение со средним µ и дисперсией σ2 . Попробуем восстановить зависимость с помощью линейных моделей над тремя наборами признаков: {x}, {x, x2 , x3 , x4} и {x, x2 , . . . , x15}. 

Соответствующие результаты представлены на рис. 1. Видно, что при использовании признаков высоких степеней модель получает возможность слишком хорошо подстроиться под выборку, из-за чего становится непригодной для дальнейшего использования.

![[Pasted image 20231010213032.png]]

# Оценивание качества модели

## Отложенная выборка

Обучающие данные разбиваются на обучающую и контрольную. После обучения на обучающей части, качество проверяется на контрольной. Если модель показывается хорошие результаты на контрольной - значит закономерности усвоены.

Проблема в том, что оценка очень сильно зависит от разбиения данных на подгруппы. Мы не знаем что было бы, если бы некоторые данные из контрольной попали в обучающую.

## Кроссвалидация

Размеченные данные разбиваются на k блоков X1, . . . , Xk примерно одинакового размера. Затем обучается k моделей a1(x), . . . , a_k(x), причём i-я модель обучается на объектах из всех блоков, кроме блока i. После этого качество каждой модели оценивается по тому блоку, который не участвовал в её обучении, и результаты усредняются и получается среднее качество оценки моделей:

$$
CV = \frac{1}{k} \sum_{i=1}^{k} Q(a_i(x), X_i)
$$
Допустим, мы оценили качество некоторого метода обучения с помощью кроссвалидации и убедились, что выдаваемые им модели хорошо обобщают. Как получить финальную модель для дальнейшего использования? Разумными будут следующие варианты: 
1. Обучить модель тем же способом на всех доступных данных. Если мы использовали кроссвалидацию, скажем, по 5 блокам, то каждая модель обучалась на 80% от общего числа объектов обучающей выборки. Если построить итоговую модель на всей выборке, то её параметры будут подобраны по большему числу объектов и можно надеяться, что качество вырастет. 
2. Если возможности обучить финальную модель нет (например, это слишком долго), то можно построить композицию из моделей a1(x), . . . , a_
3. k(x), полученных в процессе кроссвалидации. Под композицией может пониматься, например, усреднение прогнозов этих моделей, если мы решаем задачу регрессии. Позже в курсе мы выясним, что идея такого объединения нескольких моделей оказывается полезной при правильном применении.